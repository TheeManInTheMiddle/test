{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fdefc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMO\n",
    "\n",
    "# https://ai.google.dev/tutorials/python_quickstart\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f644926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini -------- test -------\n",
    "\n",
    "\n",
    "!pip install -q -U google-generativeai\n",
    "\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('•', '  *')\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "        \n",
    "# test -------------\n",
    "%%time\n",
    "response = model.generate_content(\"What is the meaning of life?\")\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "\n",
    "# method get_answer()\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('•', '  *')\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY) #------------------------------ key\n",
    "\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "        \n",
    "# test -------------\n",
    "%%time\n",
    "response = model.generate_content(\"What is the meaning of life?\")\n",
    "to_markdown(response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_answer(prompt):\n",
    "    response = model.generate_content(\"What is the meaning of life?\")\n",
    "    return response.text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc426af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method get_answer() ------------ dummy ------------------\n",
    "\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "def get_answer(prompt):\n",
    "    \n",
    "    #random_int = random.randint(0, score_range)\n",
    "\n",
    "    \n",
    "    if \"Create\" in prompt:\n",
    "        answer = 'some text {\"rq\": \"what the f***\", \"thoughts_gen\": \"hähh??\"} ett'\n",
    "    \n",
    "    \n",
    "    if \"Evaluate\" in prompt:\n",
    "        #score = gen_random_score()\n",
    "        answer = ' sjjaf {\"score\": [4,3,2,1,0], \"thoughts_as\": \"wos is???\"} jjfdfh'            # {{}} doppelt\n",
    " \n",
    "        answer = answer.replace(\"[4,3,2,1,0]\", str(gen_random_score()))\n",
    "    \n",
    "    #answer = \"answer\"     # später dummy, der zufalls answers mit dummy json ausgibt\n",
    "    \n",
    "    \n",
    "    return answer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "924040c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic score_random  context  rq_gen  thoughts_gen  score_as  \\\n",
      "0  something with AI            .      NaN     NaN           NaN       NaN   \n",
      "1  something with AI            .      NaN     NaN           NaN       NaN   \n",
      "2  something with AI            .      NaN     NaN           NaN       NaN   \n",
      "3  something with AI            .      NaN     NaN           NaN       NaN   \n",
      "\n",
      "   thoughts_as  precision  recall  f1  prompt_gen  answer_gen  prompt_as  \\\n",
      "0          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
      "1          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
      "2          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
      "3          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
      "\n",
      "   answer_as  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>score_random</th>\n",
       "      <th>context</th>\n",
       "      <th>rq_gen</th>\n",
       "      <th>thoughts_gen</th>\n",
       "      <th>score_as</th>\n",
       "      <th>thoughts_as</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>prompt_gen</th>\n",
       "      <th>answer_gen</th>\n",
       "      <th>prompt_as</th>\n",
       "      <th>answer_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic score_random  context  rq_gen  thoughts_gen  score_as  \\\n",
       "0  something with AI            .      NaN     NaN           NaN       NaN   \n",
       "1  something with AI            .      NaN     NaN           NaN       NaN   \n",
       "2  something with AI            .      NaN     NaN           NaN       NaN   \n",
       "3  something with AI            .      NaN     NaN           NaN       NaN   \n",
       "\n",
       "   thoughts_as  precision  recall  f1  prompt_gen  answer_gen  prompt_as  \\\n",
       "0          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
       "1          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
       "2          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
       "3          NaN        NaN     NaN NaN         NaN         NaN        NaN   \n",
       "\n",
       "   answer_as  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- parquet 2 github (create new file) ------------------------\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from github import Github\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "\n",
    "git_token = 'ghp_e1G7qV3fBcswLNNLhdCoQZ7Sr43ntT13xUsT' # ? expired  !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "def update_existing_df(df_new, df_to_replace):         # (dataframe, \"filename\")\n",
    "    # Initialize PyGithub with your personal access token\n",
    "    g = Github(git_token)\n",
    "\n",
    "    # Specify the repository where the Parquet file is located\n",
    "    repo = g.get_user(\"TheeManInTheMiddle\").get_repo(\"test\")\n",
    "\n",
    "    # Get the existing Parquet file from the repository\n",
    "    file_content = repo.get_contents(df_to_replace)\n",
    "    file_sha = file_content.sha\n",
    "\n",
    "    # Save the new DataFrame as a Parquet file\n",
    "    df_new.to_parquet('data_new.parquet')                    # only buffer\n",
    "\n",
    "    # Read the new Parquet file to upload\n",
    "    with open('data_new.parquet', 'rb') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Update the existing file on GitHub with the new content\n",
    "    repo.update_file(df_to_replace, 'Updating data.parquet', content, file_sha)\n",
    "\n",
    "\n",
    "def load_df(df):\n",
    "    # Initialize PyGithub with your personal access token\n",
    "    g = Github(git_token)\n",
    "\n",
    "    # Specify the repository where the Parquet file is located\n",
    "    #repo = g.get_repo('username/repository_name')\n",
    "    repo = g.get_user(\"TheeManInTheMiddle\").get_repo(\"test\")\n",
    "\n",
    "    # Get the Parquet file from the repository\n",
    "    file_content = repo.get_contents(df)\n",
    "    file_data = BytesIO(file_content.decoded_content)\n",
    "\n",
    "    # Load the Parquet file into a DataFrame\n",
    "    df = pd.read_parquet(file_data)\n",
    "\n",
    "    # Display the content of the DataFrame\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# file for test: 'data.parquet'  \n",
    "\n",
    "# load 'df_input.parquet' as df_input\n",
    "df_input = load_df('df_input.parquet')\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb135d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>score_random</th>\n",
       "      <th>context</th>\n",
       "      <th>rq_gen</th>\n",
       "      <th>thoughts_gen</th>\n",
       "      <th>score_as</th>\n",
       "      <th>thoughts_as</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>prompt_gen</th>\n",
       "      <th>answer_gen</th>\n",
       "      <th>prompt_as</th>\n",
       "      <th>answer_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[1, 0, 1, 0, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 0, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic     score_random  context  rq_gen  thoughts_gen  \\\n",
       "0  something with AI  [0, 0, 1, 0, 0]      NaN     NaN           NaN   \n",
       "1  something with AI  [1, 0, 1, 0, 1]      NaN     NaN           NaN   \n",
       "2  something with AI  [0, 0, 1, 0, 0]      NaN     NaN           NaN   \n",
       "3  something with AI  [0, 0, 0, 1, 1]      NaN     NaN           NaN   \n",
       "\n",
       "   score_as  thoughts_as  precision  recall  f1  prompt_gen  answer_gen  \\\n",
       "0       NaN          NaN        NaN     NaN NaN         NaN         NaN   \n",
       "1       NaN          NaN        NaN     NaN NaN         NaN         NaN   \n",
       "2       NaN          NaN        NaN     NaN NaN         NaN         NaN   \n",
       "3       NaN          NaN        NaN     NaN NaN         NaN         NaN   \n",
       "\n",
       "   prompt_as  answer_as  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- imports -----\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# ------- genrate random score ---------\n",
    "\n",
    "# create list with random score:\n",
    "def gen_random_score():\n",
    "    criteria_list = [\"Feasible\", \"Impactful\", \"Novel\", \"Ethical\", \"Relevant\"]    # aktuell nicht verwedet ?!!?\n",
    "\n",
    "    input_criteria = \"\"\n",
    "    random_score = []\n",
    "\n",
    "    score_range = 1               #----parametrisieren in def  -------------- hier erst mal 0 u 1\n",
    "\n",
    "\n",
    "    for item in criteria_list:\n",
    "        random_int = random.randint(0, score_range)\n",
    "\n",
    "        # ---- ?? liste mit Criteria and score\n",
    "        # input_criteria = input_criteria + item + \" = \" + str(random_int) + \", \" # Sinn ??\n",
    "        \n",
    "        # list with random score\n",
    "        random_score.append(random_int)\n",
    "    return random_score\n",
    "\n",
    "\n",
    "num_rows, num_cols = df_input.shape\n",
    "\n",
    "\n",
    "for row_index in range(num_rows):\n",
    "\n",
    "    score_random = gen_random_score()\n",
    "    df_input.at[row_index, \"score_random\"] = score_random\n",
    "    \n",
    "display(df_input)\n",
    "\n",
    "\n",
    "\n",
    "# methods\n",
    "\n",
    "#prompter generate()\n",
    "def prompter_gen(df, row_index):\n",
    "    \n",
    "    context = df[\"context\"][row_index]  \n",
    "    topic = df[\"topic\"][row_index]\n",
    "    score_random = df[\"score_random\"][row_index]\n",
    "  \n",
    "    # template von 0 .. 1 !!!!\n",
    "    prompt_template = f'Create a research question on the topic below as a negative example that intentionally does not fulfill all FINER criteria [\"Feasible\", \"Impactful\", \"Novel\", \"Ethical\", \"Relevant\"] but would receive the rating below with 0 = does not fulfill the criterion and 1 = fulfills the criterion to the full extent. Summarize also the aspects of the thougts that influenced the decission but without mentioning the criteria by name, only the keywords for the aspect. use a correct json format as only answer in the format without any newline character (\"rq\": your research questiom, \"feasible\": your aspects on feasibility, \"impactfull\", your aspects on impact .…). Topic and score: something with ai {topic} {score_random}'\n",
    "  \n",
    "\n",
    "    prompt = prompt_template\n",
    "    \n",
    "    # print(prompt)  #-------------test\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# prompter assess()\n",
    "\n",
    "def prompter_as(df, row_index):  # --------------- parametrisieren, damit auch von assess() verwendet werden kann?!\n",
    "    \n",
    "    rq = df[\"rq_gen\"][row_index]\n",
    "    \n",
    "  \n",
    "    #   score 0 ...1  !!!!!!!!\n",
    "    prompt_template = f'Evaluate the research question: \"{rq}\" in the given context in the json format according to the FINER criteria (Feasible, Impactful, Novel, Ethical, Relevant). Evaluate each aspect individually and choose a category (no = does not fulfill the criterion or yes = fulfills the criterion to the full extent but floating point numbers like 0.5 are not allowed) and give a brief explanation for the decission and also a json as in the example: [\"score\": [<list with your categories write 0 for no or 1 for yes>] ,„feasible“: <your tought>, „impactful“: <your tought>, „novel“: <your tought>, „ethical“: <your tought>, „relevant“: <your tought>]'\n",
    "    \n",
    "    \n",
    "    prompt = prompt_template\n",
    "    \n",
    "    print(\"prompt: \", row_index)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parser(answer):\n",
    "    answer_json = extract_json(answer)\n",
    "    return answer_json\n",
    "    \n",
    "    #---------------test\n",
    "    #print(answer_json)\n",
    "\n",
    "    \n",
    "    \n",
    "def extract_json(string):\n",
    "    try:\n",
    "        string = string.replace(\",}\", \"\")      \n",
    "        string = string.replace(\"”\", \"\\\"\")    \n",
    "        string = string.replace(\"“\", \"\\\"\")\n",
    "        string = string.replace(\"„\", \"\\\"\")\n",
    "        start = string.find('{')\n",
    "        end = string.rfind('}') + 1\n",
    "        json_str = string[start:end]\n",
    "        json_str = string[start:end].replace(\"'\", \"\\\"\")  \n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return json.loads('{\"errdfor\": \"no json found\"}')\n",
    "\n",
    "\n",
    "# write value in df\n",
    "def write_df(df, column, index, value):  \n",
    "    \n",
    "    \n",
    "    df.at[index, column] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1921ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  0\n",
      "prompt:  1\n",
      "prompt:  2\n",
      "prompt:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>score_random</th>\n",
       "      <th>context</th>\n",
       "      <th>rq_gen</th>\n",
       "      <th>thoughts_gen</th>\n",
       "      <th>score_as</th>\n",
       "      <th>thoughts_as</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>prompt_gen</th>\n",
       "      <th>answer_gen</th>\n",
       "      <th>prompt_as</th>\n",
       "      <th>answer_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what the f***</td>\n",
       "      <td>{\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...</td>\n",
       "      <td>[1, 0, 1, 1, 0]</td>\n",
       "      <td>{\"score\": [1, 0, 1, 1, 0], \"thoughts_as\": \"wos...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Create a research question on the topic below ...</td>\n",
       "      <td>some text {\"rq\": \"what the f***\", \"thoughts_ge...</td>\n",
       "      <td>Evaluate the research question: \"what the f***...</td>\n",
       "      <td>sjjaf {\"score\": [1, 0, 1, 1, 0], \"thoughts_as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[1, 0, 1, 0, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what the f***</td>\n",
       "      <td>{\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...</td>\n",
       "      <td>[1, 1, 0, 0, 1]</td>\n",
       "      <td>{\"score\": [1, 1, 0, 0, 1], \"thoughts_as\": \"wos...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Create a research question on the topic below ...</td>\n",
       "      <td>some text {\"rq\": \"what the f***\", \"thoughts_ge...</td>\n",
       "      <td>Evaluate the research question: \"what the f***...</td>\n",
       "      <td>sjjaf {\"score\": [1, 1, 0, 0, 1], \"thoughts_as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what the f***</td>\n",
       "      <td>{\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>{\"score\": [1, 0, 0, 0, 0], \"thoughts_as\": \"wos...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Create a research question on the topic below ...</td>\n",
       "      <td>some text {\"rq\": \"what the f***\", \"thoughts_ge...</td>\n",
       "      <td>Evaluate the research question: \"what the f***...</td>\n",
       "      <td>sjjaf {\"score\": [1, 0, 0, 0, 0], \"thoughts_as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>something with AI</td>\n",
       "      <td>[0, 0, 0, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what the f***</td>\n",
       "      <td>{\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...</td>\n",
       "      <td>[1, 0, 0, 0, 1]</td>\n",
       "      <td>{\"score\": [1, 0, 0, 0, 1], \"thoughts_as\": \"wos...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Create a research question on the topic below ...</td>\n",
       "      <td>some text {\"rq\": \"what the f***\", \"thoughts_ge...</td>\n",
       "      <td>Evaluate the research question: \"what the f***...</td>\n",
       "      <td>sjjaf {\"score\": [1, 0, 0, 0, 1], \"thoughts_as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic     score_random  context         rq_gen  \\\n",
       "0  something with AI  [0, 0, 1, 0, 0]      NaN  what the f***   \n",
       "1  something with AI  [1, 0, 1, 0, 1]      NaN  what the f***   \n",
       "2  something with AI  [0, 0, 1, 0, 0]      NaN  what the f***   \n",
       "3  something with AI  [0, 0, 0, 1, 1]      NaN  what the f***   \n",
       "\n",
       "                                        thoughts_gen         score_as  \\\n",
       "0  {\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...  [1, 0, 1, 1, 0]   \n",
       "1  {\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...  [1, 1, 0, 0, 1]   \n",
       "2  {\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...  [1, 0, 0, 0, 0]   \n",
       "3  {\"rq\": \"what the f***\", \"thoughts_gen\": \"h\\u00...  [1, 0, 0, 0, 1]   \n",
       "\n",
       "                                         thoughts_as  precision  recall   f1  \\\n",
       "0  {\"score\": [1, 0, 1, 1, 0], \"thoughts_as\": \"wos...        0.6     0.6  0.6   \n",
       "1  {\"score\": [1, 1, 0, 0, 1], \"thoughts_as\": \"wos...        0.6     0.6  0.6   \n",
       "2  {\"score\": [1, 0, 0, 0, 0], \"thoughts_as\": \"wos...        0.6     0.6  0.6   \n",
       "3  {\"score\": [1, 0, 0, 0, 1], \"thoughts_as\": \"wos...        0.6     0.6  0.6   \n",
       "\n",
       "                                          prompt_gen  \\\n",
       "0  Create a research question on the topic below ...   \n",
       "1  Create a research question on the topic below ...   \n",
       "2  Create a research question on the topic below ...   \n",
       "3  Create a research question on the topic below ...   \n",
       "\n",
       "                                          answer_gen  \\\n",
       "0  some text {\"rq\": \"what the f***\", \"thoughts_ge...   \n",
       "1  some text {\"rq\": \"what the f***\", \"thoughts_ge...   \n",
       "2  some text {\"rq\": \"what the f***\", \"thoughts_ge...   \n",
       "3  some text {\"rq\": \"what the f***\", \"thoughts_ge...   \n",
       "\n",
       "                                           prompt_as  \\\n",
       "0  Evaluate the research question: \"what the f***...   \n",
       "1  Evaluate the research question: \"what the f***...   \n",
       "2  Evaluate the research question: \"what the f***...   \n",
       "3  Evaluate the research question: \"what the f***...   \n",
       "\n",
       "                                           answer_as  \n",
       "0   sjjaf {\"score\": [1, 0, 1, 1, 0], \"thoughts_as...  \n",
       "1   sjjaf {\"score\": [1, 1, 0, 0, 1], \"thoughts_as...  \n",
       "2   sjjaf {\"score\": [1, 0, 0, 0, 0], \"thoughts_as...  \n",
       "3   sjjaf {\"score\": [1, 0, 0, 0, 1], \"thoughts_as...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- generate -----\n",
    "\n",
    "def generate(df, row_index):\n",
    "    \n",
    "    # get_data()                   # eforderliche daten?: RQ, category, \"what to otimize?\"(info: User-Input)\n",
    "    \n",
    "    prompt = prompter_gen(df, row_index)            # prompter organisiert sich daten von dfs / sonstige Info als Parameter übergeben\n",
    "    \n",
    "    answer = get_answer(prompt)\n",
    "    \n",
    "\n",
    "    # log\n",
    "    write_df(df_as, \"prompt_gen\", row_index, prompt) \n",
    "    write_df(df_as, \"answer_gen\", row_index, answer)\n",
    "    \n",
    "    answer_json = parser(answer)\n",
    "    \n",
    "    \n",
    "    return answer_json\n",
    "\n",
    "# ------ controller generate ------\n",
    "\n",
    "df_as=df_input\n",
    "\n",
    "num_rows, num_cols = df_as.shape\n",
    "\n",
    "\n",
    "for row_index in range(num_rows):\n",
    "    result_gen = generate(df_as, row_index)  # antwort als json\n",
    "# json auswerten: \n",
    "\n",
    "    #print(result_gen)\n",
    "    \n",
    "    # rq extrahieren und in df\n",
    "    if \"rq\" in result_gen:\n",
    "        rq = str(result_gen[\"rq\"])\n",
    "        write_df(df_as, \"rq_gen\", row_index, rq)                   # (df, column, index, value)\n",
    "\n",
    "\n",
    " \n",
    "    # json als Ganzes in df unter thoughts => später komplett in prompt??\"   (ggf regex, sonst problem mit fstring)\n",
    "    \n",
    "    # -------------------------------- probleme mit thougts---------------------------\n",
    "    write_df(df_as, \"thoughts_gen\", row_index, json.dumps(result_gen))\n",
    "    \n",
    "             \n",
    "             #  json 2 string:  json.dumps(json_object)\n",
    "    \n",
    "    \n",
    "# ------ assess() ---------------\n",
    "\n",
    "\n",
    "def assess(df, row_index):  #----------------- ??? welche argumente ???\n",
    "\n",
    "    prompt = prompter_as(df, row_index)\n",
    "    answer = get_answer(prompt)\n",
    "    \n",
    "    answer_json = parser(answer)\n",
    "    # score_list = extract_score(answer_json) # soll controller machen?!\n",
    "    \n",
    "    #print(\"answer_json in as \", answer_json)\n",
    "    #return answer_json      # ggf auch thoughts??!  = oder gleich in db schreiben?!?!\n",
    "    \n",
    "    # log   \n",
    "    write_df(df_as, \"prompt_as\", row_index, prompt) \n",
    "    write_df(df_as, \"answer_as\", row_index, answer)\n",
    "    \n",
    "    # thoughts machen noch probleme --------------!!!!!!!!!!!!!!!\n",
    "    write_df(df_as, \"thoughts_as\", row_index, json.dumps(answer_json))    # ---- zunächst json als though = bei Bedarf extrahieren\n",
    "    \n",
    "    return answer_json\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def calc_metrics(list1, list2):\n",
    "    \n",
    "\n",
    "\n",
    "#list1 = [1, 4, 3, 2]\n",
    "#list2 = [1, 4, 1, 0]\n",
    "\n",
    "    #precision, recall, f1_score, _ = precision_recall_fscore_support(list1, list2, average='binary') # [None, 'micro', 'macro', 'weighted']\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(list1, list2, average='micro')\n",
    "    #print(f\"Precision: {precision:.2f}\")\n",
    "    #print(f\"Recall: {recall:.2f}\")\n",
    "    #print(f\"F1-score: {f1_score:.2f}\")\n",
    "    return precision, recall, f1_score\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# ------ controller assess ------\n",
    "\n",
    "df_as=df_input\n",
    "\n",
    "num_rows, num_cols = df_as.shape\n",
    "\n",
    "\n",
    "for row_index in range(num_rows):\n",
    "    result_as = assess(df_as, row_index)\n",
    "\n",
    "    # json auswerten: \n",
    "    \n",
    "  \n",
    "    \n",
    "    if \"score\" in result_as:\n",
    "        score = str(result_as[\"score\"])\n",
    "        #write_df(df_as, \"score_as\", row_index, score)   #---------------------\n",
    "    else:\n",
    "        score = \"[999, 999, 999, 999, 999]\"\n",
    "    \n",
    "    write_df(df_as, \"score_as\", row_index, score)  \n",
    "    \n",
    "    # print(score)    #----------------- test\n",
    "\n",
    "    precision, recall, f1_score = calc_metrics(eval(str(df_as[\"score_random\"][row_index])), eval(score))\n",
    "    \n",
    "    \n",
    "    #precision = mae(eval(str(df_as[\"score_random\"][row_index])), eval(score))\n",
    "    \n",
    "    write_df(df_as, \"precision\", row_index, precision)\n",
    "    write_df(df_as, \"recall\", row_index, recall)\n",
    "    write_df(df_as, \"f1\", row_index, f1_score)\n",
    "    \n",
    "df_input = df_as\n",
    "display(df_input)    \n",
    "    \n",
    "# save results\n",
    "\n",
    "\n",
    "\n",
    "update_existing_df(df_input, \"df_output.parquet\")\n",
    "\n",
    "# check\n",
    "#df_output = load_df('df_output.parquet')\n",
    "#df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bafa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afe701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4234c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b7c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b438e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
